<seotitle>Cisco DevNet video transcripts</seotitle>

# Cisco DevNet Video Transcripts

## [MCP for DevOps - Use Cases](https://www.youtube.com/watch?v=NXFzZsvhJR8)

**Video transcript:**

Hey there, this is Shannon McFarland, head of Cisco DevNet and the Cisco Open Source Program Office. And I am back with the second of the series on MCP for DevOps. And we're going to briefly talk a little bit about a few of the many use cases that are out there that I'm seeing that customers and partners are telling me that they're gravitating to. and then we're going to build on these use cases over bunches of different demos and hands-on kind of sessions coming up here on YouTube. If you did not catch the first blog on MCP for DevOps with the architecture and components overview, that's something that you'll want to take a look at. I'll provide links for that and there's also a YouTube version of that same overview if you're aligned to video format. Let's do a recap of what we talked about on those two assets. We mentioned that model context protocol, something that Anthropic as an institution brought as an open source project, is a tool mechanism for linking into a variety of different non-AI native tool sets, APIs, services. And so it allows you to take an AI application or an agentic application and very quickly leverage the MCP SDK, which is a client to server communication flow, and leverage all kinds of tools, GitHub repos and CACD systems and file systems and databases and all of that stuff without actually having to write integration code for every one of those endpoints or every one of those tools natively inside your agents or natively inside your AI calls. And so that's kind of what MCP is about. And that's a little bit of a recap. And I think that what I talked about in both of those assets was what it was, which is a lightweight communication protocol designed to ease the toil and burden of having AI-enabled applications communicate with APIs, databases, and so forth. And also, it's just plumbing. It is a protocol, right? And so lots of protocols, they're just plumbing. But without those protocols, we don't have a standard way of actually implementing and observing and securing and connecting things together. And so MCP is very important in that regard. It's equally important to know what MCP is not. MCP is not a messaging protocol for agent agent communication. It's not an LLM. It's not a database itself. It's not even a platform. And it's not a replacement for your APIs and your data buses and all of those types of things. It's really there to lower or reduce or in some cases remove the toil of integrating with these types of systems. Now, the focus of this series is for DevNet and SecOps, right? That is really the community that is involved in the Cisco DevNet or the developer relations group at Cisco. And so some of the generic use cases that I'm seeing that apply to all of those happen to deal with leveraging the MCP software development kit, the SDK, which is a single SDK that has a client and a server component to it to handle, you know, the automation of routine tasks. So if you're, trying to generate reports across a large number of data sources, or you're trying to create repos or manage repos or create PRs and do it across a multitude of different repos or at large scale at a high frequency, and you want to do that without having to run a bunch of GitHub commands, it's really good. If you want to build Ansible playbooks or manage pipelines, These are things that are really good in an MCP environment. If you are trying to work through a unified data or action management system where your AI application is really trying to be the glue or the centralized hub for lots of diverse systems, such as maybe you're working with an observability solution with Splunk. You've got an orchestration system with Cisco NSO. You've got an AI security platform with Cisco AI Defense. and you're trying to singularly make sense of one specific bit of data or one trouble ticket or one problem area across a multitude of those different solutions or platforms. So that's yet another use case. Then there's things like it's going to help you get enhanced context and get a little bit better information that's richer and faster to help you make rapid and more accurate decision making. it's also really good you know when you are looking at compliance and security across a lot of different systems and it would normally have to take experts and a lot of lot of code to get you know visibility across different compliance systems and making sure there's security and did you do auditing and what's the trail look like on that audit so again compliance and security across a diverse number of systems MCP would be very good at. Now, one of the things that come up in the DevNet SecOps space is like, hey, I build GINJA templates for my Ansible playbooks. I have that stuff inside of GitHub or a GitLab or some other kind of repo that's taking care of basically the flow and the approvals and the storage of that. This stuff makes its way into CI like or CD like Argo CD. And then eventually I manifest all of that data and all of that tooling to some sort of outcome to something like a Cisco API. And MCP is absolutely perfect in that. And so this series that we're going through, you're going to actually see hands-on real demonstrations of how we build upon things like GitHub and database access and things like netbox inventory. And how do we feed all of that stuff into a pipeline that we ultimately use against Cisco product sets. Now, I want to take a moment to just kind of talk about a few of the things we're going to get into more technically through this series. So from a DevOps point of view, we're absolutely going to get into use cases like CACD automation, you know, code management, obviously GitHub and those types of things where we're dealing with branch management and PRs and triaging issues and, And, you know, just kind of sorting out once we go into a build environment, for example, between CICD and our manifest or artifacts, can we leverage things like Docker Scout to scan, you know, for the security of the images that we're either importing or dependent upon or even building. Infrastructure automation is another one that we're going to get into. Obvious places there where you are looking at Terraform and you're building or leveraging or manipulating your own providers. Again, Ansible playbooks all the way from zero to hero in that space. This is something that's going to be very applicable to help offload the manage of that stuff. And then things ultimately like streamline incident response where you may have a series of tools that are involved in the detection of a change inside of your GitHub environment that's going to trigger a test, that's going to trigger a deployment to staging. And then ultimately, once it's there and we've got health checks in place that feel good, then we're going to send a notification to something like Cisco WebEx, right? So there's a whole bunch of chain of things that we're going to kind of work through over a pretty lengthy series that we've got in front of us. As it relates to NetOps, a lot of that stuff all still applies, right? Where we're doing things where we are taking inventory management from NetOps or from something like NetBox, and we are making sure that that is in synchronicity with the actual real configuration state of our Nexus environment or our Catalyst environment or Meraki environment, whatever it is. And we want to, again, make sure that MCP is allowing us to, from a single client or a multiple client kind of environment, allow us to reach out and grab information through these different MCP server tools, bring them into us, let us utilize AI to mix that stuff together to give us a real-time context to go do the next thing, right? And so this would be a great area that I think that people can really do a lot of discovery. John Copiabanco, if you've not followed him, he does a great job of really talking about the NetOps use case and how you can utilize a variety of tools, PyATS and a bunch of stuff, to bring this information together, make sense of it, and then send it back out as an automated workflow. where you're detecting anomalies or you're monitoring network performance and something's not right with ISIS and you've lost a peer or latency is bad in your SD-WAN environment. You bring these things together, you kind of work through them, build a brand new manifest or a brand new script or a brand new API call to go out into, for example, your cloud infrastructure to automate the change of your environment. It could be a triggered response to auto-scale something inside your Kubernetes environment. So the NetOp use cases is probably endless in the numbers of things that you can do with it. You know, one that I started off with, the very first thing that I started off using this is I had an environment where I had a data center environment. And the, you know, the constant change to go out and make one change to an OSPF router or something like that. It was like, hey, gee, wouldn't it be cool if I could, through natural language, go and say, add a new OSPF v3 IPv6 route with this particular prefix on this particular infrastructure and allow it to go in through an MCP server, make a call to a Cisco API environment through REST or NetConf or whatever the case might be, and actually trigger the implementation of that command. And so that's a very common example of something that I would use it for. And then finally, kind of wrapping up here around some of the use cases that we're going to get into. From a SecOps point of view, this is a very exciting space where you can have proactive threat responses, where you've got AI agents, for example, that are out there looking for problems. And they could swiftly detect and mitigate a threat by utilizing the AI agentic interface that is communicating with tools. And again, MCP is not there to manage and control those agents. It's there to provide those agents access to tools. And so when you've got one or multitude of agents kind of like working in different areas of your SecOps environment, it can go out and detect these things and then start taking conditional access on them where you can maybe want to go and just simply adjust a firewall in the Cisco Secure firewall. Or it could be that you've got endpoints that are misbehaving with malware and you got Cisco Secure endpoint that triggers something into the environment we go through when that AI agent starts talking to other AI agents saying, okay, how strict do we get? Do we just isolate this one? Do we isolate the subnet? Do we isolate the site? And so you can begin to start gluing those things together. And then you, again, like we did with NetOps, you then introduce this automated vulnerability management, right? It's like, okay, what was the root cause of this? And how do we make sure that it doesn't happen again? And so we can take that state or that knowledge of all of those complex inner workings on the MCP server side, the tool side, bring them together, leverage AI, leverage other observability platforms that can help us understand context, and then build a brand new automated strategy that is better and faster at detecting and taking action there. And right, that's that next step of really taking the information and then doing something with it. And then finally, end-to-end real-time incident orchestration. And that is where each one of these tools that set off an alarm bell as we go through the pipeline of a threat. We can turn around and bring a comprehensive incident response to it, not only to the things that we talked about where we're actually taking action to just kind of stop the bleeding, but we can also go through and learn programmatically across these various complex systems to detect things faster again and proactively build better firewall rules, better malware detection, and better alerting. And so I'm pretty excited about this space. I'm not a huge security person day to day, but this is definitely something when I talk to our customers at Cisco Live, where they actually are really excited about the SecOps space with utilizing MCP across a variety of different tools. So that's a little bit of a walkthrough. The blog post that I'll refer you to has definitely got a lot more context to it. There's some graphics there that kind of spell out some of the things that I'm talking about here. But I'm pretty excited about what we've got coming up in this series, what we're going to do next as it relates to gluing together tools like GitHub and Argo CD and Cisco Firewall and Meraki Dashboard and Cisco Ice and a bunch of these things together and really start to stack together a pretty nice looking operationally centric use case story for you. So I appreciate it. I hope you stick around. Thanks. Have a good day.

## [SRE & DevOps Insights with Matt Shooshtari. Tools, Scaling & Best Practices | DevNet Decoded](https://www.youtube.com/watch?v=JvcXITepzpU)

**Video transcript:**

Hello and welcome to the Cisco DevNet channel. My name is Oleksii and in this video we will discuss SRE and Dev Ops at DevNet with Matt Shushtari, DevNet SRE technical leader. It's a real pleasure to have you here, Shush. We are all excited to hear about your career paths and role. Thank you for having me. You know, I've started by helping people with technology needs probably since I was little, you know, from hooking up stereos to hooking up cloud stuff. And some of the biggest parts for me were, you know, when I was in the Air Force, being able to help different teams upgrade their computers to, you know, Windows 2000 from NT. and then later on being able to help teams with build environments, deploying things to the cloud, and helping startups with new software. And all of these things sort of led me towards how do I automate? How do I improve? How do I get time for myself to do these projects? And how do I help teams become successful? So that's kind of a lot of different evolution for me. and through my force of working at startups, I met some great people that worked at Cisco and they wanted me to come help on some of their projects as well. And I've actually been here probably as long as most of my other career just because there are so many great things to work on and exciting projects. You never get bored. So I'm happy to be here and it's been a really great career. Yeah, amazing journey. Okay, Shush. And let's jump and talk a little bit about DevNet, DevOps and SRE practice. How big is our DevNet cluster and which services do we have? What challenges do we face in scaling and managing it? Yep. So we have, for our production cluster, it's fairly large. We have 13 MX large five or MX large five nodes. And we have those across three availability zones. On there, we have 191 deployments. So these are, you know, different Kubernetes workloads. All of them are defined with Helm charts. You know, I think some of the challenges that we have managing this infrastructure is that it's grown very organically. And so, you know, there are some things on there that may be used, you know, may not be used, but we're really trying to kind of in the progress of understanding it, make sure that, you know, everything is sized correctly, everything, everything runs, you know, as efficiently as it can, and that we have, you know, the right high availability, that workloads are distributed. We want to spend time on the items that are running and working and try to remove some of the other things that aren't. So I think that's the biggest challenge for us, and it leads us towards better security practice and, of course, cost savings. Yeah, yeah, this is cool. And what tools and technologies do we use to automate our workloads, and how do they improve efficiency in our SRE and DevOps progress? So a lot of the tools that we have are very traditional. So we have Helm as a product for building Kubernetes workloads. We do have a product internally grown. It's called Mention that we use for deploying these workloads to our Kubernetes clusters. These are EKS clusters. And when we do the deployment, this tool is really, it'll show you what services there are. and it's very much like Argo CD. What impresses me the most about this particular tool, and I want to go to the demo section, I'll show it there, is that this was created before Argo CD. And so it doesn't quite have some of the features and functionality that you'd like, but it actually works very well. And it does allow developers to make changes to the Helm manifest, change the version of the applications that they're using, and then of course assign those newer versions to the cluster to be deployed so it really streamlines that workflow of course you know for getting the containers building the software we use traditional tools like jenkins uh we you know use github of course uh we pull the source we build it we deploy with docker containers you know we store those docker containers in uh in the Amazon's registry. We also have some Cisco registry that we store containers in as well. So depending on where we need to consume them, we store them closest to that location. Yeah, maybe you can show to our audience some tools that we use. Yeah, sure thing. Let me get this shared real quick. All right. So here is the dimension tool. And so when you log on, you'll see, you know, these are the clusters that we have. You'll see that we have our different environments, staging integration a backup cluster we have clusters that run the Cisco Learning Labs production environment and then of course a backup production cluster allows us a place to fail over to if we need to have that and then as we go this dashboard gives you a good view of you know the services that are running the total number of services some of the health about those it gives us a little bit about what's been updated so you can see that these particular services have been updated recently and then this is a nice diagram of you know what does the whole landscape look like for these services as we go here this gives you a look at you know the tiles so i want to say you know here is a service here if it's healthy or not you can get information about it so if we look at the service details you know you'll see information about the pods that are running uh information about you know any tests and things like that so uh when you when you look at this it's again very much like argocd but very cool that it was developed before that for me before i joined the devnet team you know i hadn't heard of it and i was wondering you know well what is that is it is it like argocd like no we've had this for a while and you know seeing it it's actually very cool software so that that's that part and of course github we just use github for repositories we have an internal github that we use for that um and then we're able to build with Jenkins deploy to the container registry and then pick those up here into our EKS environment yeah awesome and which security and monitoring tools do you use to to manage all this oh excellent so you know as i went through a lot of this was monitored manually and when you saw this you know it was it took a lot of human hours to you know check something audit something uh present present evidence for this and as you know as i was doing this audit process we looked and you know there was a tool git guardian that had been used in other organizations but when working with our build environment security uh partner team they said well we have a tool that we use it's called legit security and i was like okay you know what is this tool and not only does it do the same things where you know it's checking for uh leaked credentials it's checking for access to repositories you know it's going to make sure that your um you know that your you know your builds and and the way that your source code that you have least privilege access to it but it also interacts with your container registries it plugs into jenkins and it gives you a complete view of you know what's going on in your build pipeline from source to production which you know that helps us quite a bit and so that tool is uh legit and you know here's an example the dashboard see if i can get this zoomed in like this but you know again it tells you about you know what's going on with your secrets how to prioritize them what source control branches and everything they might be in and how this tool helped us is when we were doing the audit and we were doing this manual process you know it was a lot of checking each and every repository uh we have uh you know many repositories at devnet and to take screenshots and analyze each of these repositories individually you know it would have taken months you know just constant work and nothing else would have gotten done and so by employing the tool legit security we're able to go and you know bring all of that evidence collection all of that compliance and meet our compliance goals and and you know got done ahead of time in fact you know we heard a lot of positive feedback about how we were able to get this done so quickly and we owe that to the relationship with the build environment security team and their recommendation and help uh in setting up this legit tool so that that to us was a you know a boom uh let's see here those ones are for the the ai will go over those after one i'm not sure i'm not hearing you at this point oh i'm sorry i'm sure um yeah ai agents and the AI technologies is trending now. I'm wondering how do you adapt and utilize them in your daily job? So in my daily job we're looking at you know manual work that comes in. We still get requests from engineers that need help with access troubleshooting. We get requests from you know compliance teams to produce evidence. We get requests from other teams for, you know, adding access for security tools. And then of course, we need to audit our environment as, you know, as staff members change, as our, you know, security landscape changes. And that could take a lot of time. We're a very small team. So it's myself and Jerry. And it takes us, you know, quite a bit of time to keep in touch with all this landscape. And so as we were looking at this, we also had a request for, you know, let's do some agentic things. And what we came up with was doing a SRE agent we're calling CIRA. And CIRA is helpful because all of our knowledge base and documentation, things that we put in there, which is, you know, how do we do things? You know, where does this information exist? Where does that information exist? It's all consolidated now in CIRA. So, you know, you don't have to worry about, do I have that link? Do I have this? You know, where am I going to find that? That's actually the first challenge that we had and we have solved with CIRA by bringing that knowledge in and ingesting that into reg for our agents. The second set of things that we have are frequent audits. So we have a lot of things in our source control, making sure that access to internal and external teams matches what is supposed to be there. And we don't often know if team members that are in other teams or sister teams or in partners that we work with, whether or not those accounts are active, not active, if they change teams, if they no longer have a need to access that source control. We don't get that information in real time. And it's very hard to ensure that that security is met. So what we're doing now with CIRA is we're using the MCP model context protocol tool, and we're going to integrate with GitHub. And then we're also going to write our own MCP tool, our own MCP server to interface with Cisco's Active Directory or LDAP. And so by using those tools, our CIRA agent will be able to check the manifest of users in source control and verify that against the manifest of users who should be in a particular group and if they are active employees if they are in certain groups now this agent can go and ensure that the manifest or the access reflects the employees that should be there this was something that may take a full-time job for somebody and now CIRA is able to perform that full-time job on our behalf and as we go through we're going to expand to do you know more and more things with syra so uh here i have a couple of things you know i've asked sarah i said tell me about the devnet sre team and then of course it's able to use reg and then quickly summarize that and then i said uh based on uh context that net uses these tools it talks about an automation repo this is github You know, we do secret rotation. It's telling us where in our internal repository we have that process. It talks about where we renew certificates. And, of course, Cisco's internal vault that we use. So these things, you know, it's all information. But if you have a new hire, if you're busy working on one project or another and you need that information, CIRA is going to be able to provide it. You know, it's just like having a personal assistant and having staff at the same time. So I really love it. It's fun to work on. And, you know, my colleague, Jerry, he's done a great job in helping to develop this interface and some of the things where, you know, it's making our lives really that much better. Yeah, let's have some example. So you have some database with all this available, like ticketing access, all DevOps and SRE information, and you utilize retrieval augmented generation and utilize, as I see, open access model to help you to navigate through all this information and complete related tasks. Am I right? That's correct. And we've been, as part of the audit process, and as we go through resolving these issues, we're documenting all of this process. Right now, we're documenting it in Word documents, in wikis. We're ingesting wikis that we have. We're ingesting SharePoint that we have. But we want to also add Asana, which is our project management tool. is very much like jira but you know it's something that is different for me uh i've used jira in the past but asana is like jira and i think there's an opportunity to ingest that data as well so uh not only could syra you know collect data from there and be able to improve responses and understand solutions but syra could also work as a you know personal assistant and could help remind you and say you know what does my schedule look like how should i prioritize tasks that i have you know based on the due dates and it would be able to understand this is what your quarterly plan looks like these are the tasks that you have scheduled you know and help you get those things done i think you know for me i've got a little bit of adhd and having a colleague like syrah help me you know is immeasurable so i you know i'm appreciative of that and you know as i go through i'm trying to lean on our automation and ai tools as much as possible yeah it's awesome example thanks for sharing this uh we released a lot of new features like summarization and ai assistance in our ai docs or new features in learning labs i'm interested how ci cd process looks these days now yes so uh currently we're using jenkins and we're going to be moving from uh one internal hosted jenkins to a different one which has a little bit more capability but as we're doing this we are looking at doing this ai first so that when you want builds when you want to initiate a build or change some features in a build that rather than going to the jenkins portal you'll be able to use a mcp tool in conjunction with sira agent to make those changes to give you information about a build, to initiate a build, to tell you about the artifacts for a build, and also if you have some failures in your build to tell you, you know, where did this build fail? You know, so many times development teams that I've worked with have looked and, you know, they see a big, you know, build blog in Jenkins and maybe, you know, somewhere in there there's two or three lines that actually mean this is why the build failed you know whether it's an access problem whether it's a compilation problem whether it's an integration test problem and you know being a devops engineer you're always asked you know my build failed i got a message that my build failed why did my build fail and so i would like you know syra or a different agent depending to be able to not just interact with that, but to tell you in plain English or in the language that you might use why that build failed and help you understand how to fix it. I think that would be a huge accelerator. And of course, the opportunity I see in moving Jenkins from one system to another is that we can do it in an agent first method. um yeah i have some thanks for mentioning about this um yeah we have uh three four minutes left maybe there is something else that you want to share with audience yeah so i think as you know as i've worked with the uh demnet sre team i found that really that the team is fantastic you know there are so many opportunities uh they've been a small team and they've done a lot of things to you know get done what they need to do it very uh very efficiently And I think, you know, what I found that I can help and bring to the team and, you know, and work on this collaboration is I can help write these MCP tools. I can help with the prompt engineering because I have some understanding of, you know, how to interact with customers on getting the tools to do what they need to need to have done. I've been doing this, I think, most of my career, as I talked about, from helping people hook up stereos to building computer images for, you know, military workstations, all the way to, you know, of course, helping build cloud systems and automate with, you know, YAML languages or with Python. And so this is just taking it a little bit further now where the tool is MCP. It's designed in an agentic way. So rather than a human interfacing with the tool, it presents itself in a way that an agent can interface with it. And then given, you know, given the right prompts and understanding of what developers and what teams need, you're able to accomplish something great. And so I'm really happy to be part of the team, really happy to be able to bring this acceleration and help the team have a really good experience with their platform, with their development. So that, I think, is one of the greatest things about being on the DevNet SRE team. Yeah, awesome. Thank you, Shush, for sharing this information with our audience. Thank you again. No worries. Take care. Bye-bye.

## [New Always-On DevNet Sandbox for Cisco Catalyst 8000 & Catalyst 9000](https://www.youtube.com/watch?v=eqAwzJge1RU)

**Video transcript:**

Hi everyone, welcome to DevNet Sandbox. Today I'm going to be looking at the brand new iOS XE Catalyst 9000 Always On Sandbox, as well as an update to the existing iOS XE Catalyst 8000 Always On Sandbox. My name is Joseph Kearns. I am a technical lead with the DevNet Sandbox team and was heavily involved in the build out of these labs. So let's just get straight into it. I am sharing the DevNet Sandbox portal. The two labs which we're going to look at are this guy here, this Catalyst 8000 Always On, and the 9000 Always On. Clicking on these will bring out the instructions, just an overview of what's supported. Remember, these are always on labs, so they're primarily focused on very simple API calls, some use cases to help you with your automation around iOS XE. Access details are discussed, and I'll show that in a few minutes, as well as some other interesting links down here. Some Python code samples, some scripts, as well as some learning labs. And it's exactly the same for the 9000. Okay, a couple of different links in here. We have GNMI which is supported on the 9000 and we've opened a port for that as well. So let's just go back to the 8000 and spin up a lab. We're going to launch this. Two days is fine. Now the update we've made here is that we don't provide a single username and password for everyone to use. What we're doing here is we're creating unique credentials using AAA. We then test them. We test the credentials to connect using SSH and RESTconf to make sure that they're good. And once these tests are passed, we output them to the user. So these should output here in a second on the IO interface. This is an actual admin view. so don't worry if you're not seeing all these options. The information you need will either be on the IO view or the quick access view in your tab. So we have a unique username generated, a password, and the actual server. So let's just copy out the password and make sure we can connect to the 8000. I'm actually already connected, but let's just reconnect. paste it in yeah we have message of the day let's just show privilege to make sure we have 15 that's fine we can show run as well showing what we have some triple a some the the config on the box itself is pretty basic triple a management management interface and rest conf net conf opened up as well. So you can see here already that we have some loopback interfaces created by users, some on Python, NetConf, NetConf and ResConf. And we also have some other information down here regarding Yang interfaces as well. But Yang and NetConf and ResConf are all Privilege 15. You have read-write access to this box. Important message though, this is a shared resource. We have multiple users accessing this at the same time. So just be careful when writing to the device that you don't make any changes to the management interface, which is Gigabit Ethernet 1 or the AAA stuff. What happens is we have some monitoring in the background that connects connectivity. If that fails, we reset back to an early config. okay so just be wary of that let's just end this okay so that's going to end let's just go back to self-service we're going to have a look at the 9000 which is exactly the same setup let's just launch this guy okay two days is fine launch again we're going to create credentials The 9000 is a separate server. So we create separate credentials. And just while that is spinning up, we do have other always-on labs here, which are going to go through a similar change. So you can see here that we have, say, OpenNXOS. And here we provide a username and password for everyone to use. Just be aware that this is going to change in the next couple of months or so. that this is going to use the same password as the same architecture as the 8000 and 9000 and that goes for all the always on labs that we have so if i just go back to my 9000 sandbox it should be there it is okay all tests passed okay everything good so let's just look at our we have generated username and password which is good okay let's just copy these out and connect to it let's exit out of the 8k okay we're connecting to the 9k now let's just go back in and get the password there we go message of the day again um a different host name but that's fine show run again full privilege 15 we have some config written here by users which is fine everything all the connectivity is good gigabit zero slash zero that is management interface the vrf so don't touch that please or else it'll reset back and we also have netconf restconf as well as the GNXI command or the API which is available as well so that's it I just wanted to create this short video to show you the updates if you have any feedback you can go to the sandbox support forum or a lot of you have provided feedback but we would we'd love to get more if you need a dedicated 8k environment okay which a lot of people do we recommend going to reserve this guy here iOS XE on cat 8k and you can see here that this lab there's a couple of notes in this lab we have iOS XRV Nexus 9k as well as a few other 8ks as well using QEMU virtualization but there is an 8k in here as well that you can access and you have total isolation on that 8k so you can do whatever you need to it we are planning a separate 9k sandbox as well but that's a little bit in the future. So thanks a lot for your attention. Please provide feedback. We'd love to hear from you. Thanks a lot.

## [AI Defense Policies: Protecting Your Agents from Prompt Injection & Privacy Risks](https://www.youtube.com/watch?v=PTgb01WsOAI)

**Video transcript:**

Hi, my name is Oleksii Borysenko. In this video we will review how to use AI defense policies for your AI agent or AI assistants. AI defense protects against risk from AI development, deployment and usage. It combines new AI detection and defense tools with existing Cisco Security Cloud network, visibility and enforcement. I have created a policy to blocked prompt injection and a privacy guardrail that help reveal personally identifiable information as a part of prompts or responses in our AI agents interaction. Let's start with a simple AI agent that can interact with the large language model and internal databases. We will use a request that contains the email: generate an introduction email based on template intern you for CTO@acme.com and we will receive the following response: this request violates rules PII email addresses. Then we will try with prompt injection. We will use this prompt injection and we will receive response: this request violates rules prompt injection. We can find all our event logs on this page. You can find here information on what policies was applied, conversation and rules matches. AI Defense provides two primary methods for integrating applications: the API method and the gateway method. In this demo we wrote traffic through the AI gateway and all requests go through it. Let's see what it looks like. We have here integration connection, we have gateway URL that we set as an environment variable and there is a code snippet to test your integration.
